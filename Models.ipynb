{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16a657af",
   "metadata": {},
   "source": [
    "# Introducing the test models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bfd50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import skfuzzy as fuzz\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, cohen_kappa_score, silhouette_score,\n",
    "    confusion_matrix, classification_report, adjusted_rand_score,\n",
    "    normalized_mutual_info_score\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc3ab66",
   "metadata": {},
   "source": [
    "## 4.3 Supervised Learning Approach  \n",
    "(logistic regression, decision tree, Naive Bayes and K-nearest neighbor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def07d13",
   "metadata": {},
   "source": [
    "Multinomial Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2addc304",
   "metadata": {},
   "source": [
    "## 4.4 Unsupervised Learning Approach  \n",
    "(hard) k-means, fuzzy C-means and Gaussian mixture models. Make use of PCA\n",
    "for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34ab63e",
   "metadata": {},
   "source": [
    "##### Load and prepare the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1011685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data feature matrix and labels ## LATER ON WE CAN REMOVE THE PROMPT AND JUST LOAD THE CSV\n",
    "try:\n",
    "    df = pd.read_csv(\"features.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: features.csv not found. Please ensure the file is in the current directory.\")\n",
    "    exit()\n",
    "\n",
    "# Identify Non-Feature columns\n",
    "Non_feat_columns = ['activity', 'trial', 'student', 'window_idx']\n",
    "\n",
    "#Drop the non-feature columns so that we only have the features left\n",
    "X = df.drop(columns=Non_feat_columns, errors='ignore')\n",
    "\n",
    "# We use the activity column for evaluation later (since, during recordings we have labeled each entry with an activity).We don't use it for clustering since K-Means is unsupervised.\n",
    "y_true = df['activity'].astype('category')\n",
    "Nr_clusters = y_true.nunique() # Counts the number of unique activities and assigns it to Nr_clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7023cc1",
   "metadata": {},
   "source": [
    "##### Performing PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81e9846a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use StandardScaler from sklearn to standardize the features. It centers the data (mean=0) and scales it (std=1).\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#Since we are going to visualize the clusters in 2D, we use PCA to reduce the dimensionality of the feature space to 2 principal components (PC1, PC2)\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd0de78",
   "metadata": {},
   "source": [
    "##### Creating a hungarian algorithm function:\n",
    "It is needed since the assignment asks to evaluate all models using Accuracy, Cohen's Kappa and F1 scores. Those metrics are usually used for supervised learning only, hence we would need to create a ground truth reference for a comparison in the unsupervised models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40302c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hungarian_align(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Map cluster IDs to ground-truth labels using the Hungarian algorithm.\n",
    "    Returns y_pred_mapped (same shape as y_pred).\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "\n",
    "    labels_true = np.unique(y_true)\n",
    "    labels_pred = np.unique(y_pred)\n",
    "\n",
    "    # Contingency table: rows=true labels, cols=predicted clusters\n",
    "    contingency = pd.crosstab(\n",
    "        pd.Series(y_true, name=\"true\"),\n",
    "        pd.Series(y_pred, name=\"pred\"),\n",
    "        dropna=False\n",
    "    )\n",
    "    contingency = contingency.reindex(index=labels_true, columns=labels_pred, fill_value=0)\n",
    "\n",
    "    # Hungarian on cost = -counts (maximize overlap)\n",
    "    cost = -contingency.to_numpy()\n",
    "    row_ind, col_ind = linear_sum_assignment(cost)\n",
    "\n",
    "    # Build mapping for assigned columns\n",
    "    mapping = {}\n",
    "    for r, c in zip(row_ind, col_ind):\n",
    "        true_lab = contingency.index[r]\n",
    "        pred_lab = contingency.columns[c]\n",
    "        mapping[pred_lab] = true_lab\n",
    "\n",
    "    # Map any leftover pred clusters to their majority true label\n",
    "    leftover_pred = set(labels_pred) - set(mapping.keys())\n",
    "    for pl in leftover_pred:\n",
    "        col = contingency[pl]\n",
    "        mapping[pl] = col.idxmax()\n",
    "\n",
    "    return np.array([mapping[p] for p in y_pred])\n",
    "\n",
    "def eval_supervised_style(name, y_true, y_pred_raw):\n",
    "    \"\"\"\n",
    "    Supervised-style metrics after aligning clusters to labels:\n",
    "    - Accuracy\n",
    "    - Cohen's Kappa\n",
    "    - Macro F1\n",
    "    Returns mapped predictions too.\n",
    "    \"\"\"\n",
    "    y_pred_aligned = hungarian_align(y_true, y_pred_raw)\n",
    "    acc = accuracy_score(y_true, y_pred_aligned)\n",
    "    kappa = cohen_kappa_score(y_true, y_pred_aligned)\n",
    "    f1 = f1_score(y_true, y_pred_aligned, average=\"macro\")\n",
    "    print(f\"\\n--- {name} (Supervised-style metrics) ---\")\n",
    "    print(f\"Accuracy       : {acc:.4f}\")\n",
    "    print(f\"Cohen's Kappa  : {kappa:.4f}\")\n",
    "    print(f\"F1-Score (Macro): {f1:.4f}\")\n",
    "    return acc, kappa, f1, y_pred_aligned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d085fe02",
   "metadata": {},
   "source": [
    "##### K-means (hard) model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddc5ce7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- K-Means (Supervised-style metrics) ---\n",
      "Accuracy       : 0.5525\n",
      "Cohen's Kappa  : 0.4258\n",
      "F1-Score (Macro): 0.4925\n"
     ]
    }
   ],
   "source": [
    "#Create and train the K-Means model\n",
    "K_means_model = KMeans(\n",
    "    n_clusters=Nr_clusters,\n",
    "    init='k-means++', # Smart initialization method\n",
    "    max_iter=300,\n",
    "    n_init=10, # Run 10 times with different centroids to find the best result\n",
    "    random_state=33\n",
    ")\n",
    "K_means_model.fit(X_scaled)\n",
    "K_means_model_labels = K_means_model.labels_ # Get the cluster assignments (labels)\n",
    "\n",
    "# Supervised-style metrics\n",
    "acc_km, kappa_km, f1_km, y_km_aligned = eval_supervised_style(\"K-Means\", y_true, K_means_model_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f4b60d",
   "metadata": {},
   "source": [
    "##### Fuzzy C-means model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9358e31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fuzzy C-Means (Supervised-style metrics) ---\n",
      "Accuracy       : 0.7121\n",
      "Cohen's Kappa  : 0.6401\n",
      "F1-Score (Macro): 0.6992\n"
     ]
    }
   ],
   "source": [
    "X_scaled_Transposed = X_scaled.T  # Transpose the current dataframe since skfuzzy expects (features, samples)\n",
    "cntr, u, _, _, _, _, fpc = fuzz.cluster.cmeans(\n",
    "    data=X_scaled_Transposed,\n",
    "    c=Nr_clusters,\n",
    "    m=2.0,\n",
    "    error=1e-5,\n",
    "    maxiter=1000,\n",
    "    init=None,\n",
    "    seed=33\n",
    ")\n",
    "Fuzzy_C_means_model_labels = np.argmax(u, axis=0)\n",
    "\n",
    "# # Unsupervised metrics\n",
    "# fcm_sil, fcm_ari, fcm_nmi = eval_unsupervised(\"Fuzzy C-Means\", y, fcm_labels)\n",
    "# print(f\"FCM partition coefficient (FPC): {fpc:.4f}\")  # diagnostic\n",
    "# Supervised-style metrics\n",
    "acc_fcm, kappa_fcm, f1_fcm, y_fcm_aligned = eval_supervised_style(\"Fuzzy C-Means\", y_true, Fuzzy_C_means_model_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d23654",
   "metadata": {},
   "source": [
    "##### Gaussian Mixture model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70801347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Gaussian Mixture (GMM) (Supervised-style metrics) ---\n",
      "Accuracy       : 0.6381\n",
      "Cohen's Kappa  : 0.5439\n",
      "F1-Score (Macro): 0.6320\n"
     ]
    }
   ],
   "source": [
    "gmm = GaussianMixture(n_components=Nr_clusters, covariance_type=\"full\", random_state=33, n_init=5)\n",
    "gmm.fit(X_scaled)\n",
    "gmm_probs = gmm.predict_proba(X_scaled)\n",
    "gmm_labels = np.argmax(gmm_probs, axis=1)\n",
    "\n",
    "# # Unsupervised metrics\n",
    "# gmm_sil, gmm_ari, gmm_nmi = eval_unsupervised(\"Gaussian Mixture (GMM)\", y, gmm_labels)\n",
    "# Supervised-style metrics\n",
    "acc_gmm, kappa_gmm, f1_gmm, y_gmm_aligned = eval_supervised_style(\"Gaussian Mixture (GMM)\", y_true, gmm_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e62ba7d",
   "metadata": {},
   "source": [
    "##### Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f563cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ Supervised-Style Metrics Summary ================\n",
      "\n",
      " Method  Accuracy  Cohen's Kappa  F1-Score\n",
      "K-Means  0.552529       0.425804  0.492490\n",
      "    FCM  0.712062       0.640083  0.699162\n",
      "    GMM  0.638132       0.543883  0.631993\n"
     ]
    }
   ],
   "source": [
    "sup_style_summary = pd.DataFrame([\n",
    "    (\"K-Means\", acc_km,  kappa_km,  f1_km),\n",
    "    (\"FCM\",     acc_fcm, kappa_fcm, f1_fcm),\n",
    "    (\"GMM\",     acc_gmm, kappa_gmm, f1_gmm),\n",
    "], columns=[\"Method\", \"Accuracy\", \"Cohen's Kappa\", \"F1-Score\"])\n",
    "\n",
    "print(\"\\n================ Supervised-Style Metrics Summary ================\\n\")\n",
    "print(sup_style_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c8dd71",
   "metadata": {},
   "source": [
    "##### Plotting and Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74445b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we assign labels to the cluster IDs based on the majority class within that cluster.\n",
    "# It helps with interpreting what each cluster represents.\n",
    "df_labeled_temp = pd.DataFrame({\n",
    "    'Cluster_ID': K_means_model_labels,\n",
    "    'True_Activity': y_true\n",
    "})\n",
    "\n",
    "# Create the Contingency Table (Cross-Tabulation)\n",
    "contingency_table = pd.crosstab(\n",
    "    df_labeled_temp['Cluster_ID'],\n",
    "    df_labeled_temp['True_Activity']\n",
    ")\n",
    "\n",
    "# Determine the majority activity for each cluster ID\n",
    "cluster_to_activity_mapping = {}\n",
    "for cluster_id in contingency_table.index:\n",
    "    majority_activity = contingency_table.loc[cluster_id].idxmax()\n",
    "    cluster_to_activity_mapping[cluster_id] = majority_activity\n",
    "\n",
    "unique_clusters = np.unique(K_means_model_labels) # Get the unique cluster IDs\n",
    "\n",
    "\n",
    "\n",
    "#Plotting and Visualization\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "cmap = plt.cm.get_cmap('tab10', len(unique_clusters))\n",
    "\n",
    "# Iterate through each cluster ID to plot it separately, which allows for a clean legend\n",
    "for cluster_id in unique_clusters:\n",
    "    indices = K_means_model_labels == cluster_id\n",
    "    activity_name = cluster_to_activity_mapping[cluster_id]\n",
    "\n",
    "    # Plot the subset of points for this cluster\n",
    "    plt.scatter(\n",
    "        X_pca[indices, 0],              # PC1 on the X-axis\n",
    "        X_pca[indices, 1],              # PC2 on the Y-axis\n",
    "        c=[cmap(cluster_id)],           # Assign the color from the colormap\n",
    "        label=f'{activity_name} (ID {cluster_id})',  # Use the Activity Name + ID\n",
    "        alpha=0.8,\n",
    "        s=24,\n",
    "    )\n",
    "\n",
    "# Centroids must also be transformed to the PCA space for plotting\n",
    "centroids = K_means_model.cluster_centers_\n",
    "centroids_pca = pca.transform(centroids)\n",
    "plt.scatter(\n",
    "    centroids_pca[:, 0],\n",
    "    centroids_pca[:, 1],\n",
    "    marker='X',\n",
    "    s=150,\n",
    "    linewidths=2,\n",
    "    color='black',\n",
    "    edgecolors='white',\n",
    "    label='Centroids'\n",
    ")\n",
    "\n",
    "\n",
    "# Set labels, title, and legend\n",
    "plt.xlabel(f\"Principal Component 1 ({explained_variance[0]*100:.1f}% Variance)\")\n",
    "plt.ylabel(f\"Principal Component 2 ({explained_variance[1]*100:.1f}% Variance)\")\n",
    "plt.title(f\"K-Means Clustering (K={Nr_clusters}) Results in PCA Space\")\n",
    "plt.legend(title='K-Means Cluster ID', loc='best')\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "\n",
    "#Evaluation of the model using the true labels for reference\n",
    "\n",
    "\n",
    "ari = adjusted_rand_score(y_true, K_means_model_labels)\n",
    "nmi = normalized_mutual_info_score(y_true, K_means_model_labels)\n",
    "\n",
    "\n",
    "print(f\"Adjusted Rand Index (ARI): {ari:.4f} (0.0=random, 1.0=perfect match)\")\n",
    "print(f\"Normalized Mutual Information (NMI): {nmi:.4f} (0.0=no mutual info, 1.0=perfect match)\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
